#!/usr/bin/env python
# coding: utf-8

# In[ ]:


#Dream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan. Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers.


# Dream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan. Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers.

# In[ ]:


import numpy as np
import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold   #For K-fold cross validation
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn import metrics
get_ipython().run_line_magic('matplotlib', 'inline')


# In[ ]:


data_train = pd.read_csv('D:\\Machine Learning\\Machine Learning\\train.csv')
data_test = pd.read_csv('D:\\Machine Learning\\Machine Learning\\test.csv')

data_train.head()

# In[ ]:


data_train.shape


# In[ ]:

    
data_test.shape


# In[ ]:


data_train.head()


# In[ ]:


data_train.describe()


# In[ ]:


data_test.describe()
# data_test.head()


# In[ ]:


data_train.isnull().sum()


# In[ ]:


data_test.isnull().sum()


# In[ ]:


data_train['Gender'].value_counts()


# In[ ]:


data_test['Gender'].value_counts()


# In[ ]:


def get_combined_data():
    train = pd.read_csv('D:\\Machine Learning\\Machine Learning\\train.csv')
    test = pd.read_csv('D:\\Machine Learning\\Machine Learning\\test.csv')
    targets = train.Loan_Status
    train.drop('Loan_Status', 1, inplace=True)
    combined = train.append(test)
    combined.reset_index(inplace=True)
    combined.drop(['index', 'Loan_ID'], inplace=True, axis=1)
    return combined


# In[ ]:


combined = get_combined_data()
combined.describe()


# In[ ]:


def impute_gender():
    global combined
    combined['Gender'].fillna('Male', inplace=True)


# In[ ]:


def impute_martial_status():
    global combined
    combined['Married'].fillna('Yes', inplace=True)


# In[ ]:


def impute_employment():
    global combined
    combined['Self_Employed'].fillna('No', inplace=True)


# In[ ]:


def impute_loan_amount():
    global combined
    combined['LoanAmount'].fillna(combined['LoanAmount'].median(), inplace=True)


# In[ ]:


def impute_credit_history():
    global combined
    combined['Credit_History'].fillna(2, inplace=True)


# In[ ]:


combined['Credit_History'].value_counts()


# In[ ]:


impute_gender()


# In[ ]:


impute_martial_status()


# In[ ]:


impute_employment()


# In[ ]:


impute_loan_amount()


# In[ ]:


impute_credit_history()


# In[ ]:


combined.isnull().sum()


# In[ ]:


print(combined.head())


# In[ ]:


def process_gender():
    global combined
    combined['Gender'] = combined['Gender'].map({'Male':1,'Female':0})


# In[ ]:


def process_martial_status():
    global combined
    combined['Married'] = combined['Married'].map({'Yes':1,'No':0})


# In[ ]:


def process_dependents():
    global combined
    combined['Singleton'] = combined['Dependents'].map(lambda d: 1 if d=='1' else 0)
    combined['Small_Family'] = combined['Dependents'].map(lambda d: 1 if d=='2' else 0)
    combined['Large_Family'] = combined['Dependents'].map(lambda d: 1 if d=='3+' else 0)
    combined.drop(['Dependents'], axis=1, inplace=True)


# In[ ]:


def process_education():
    global combined
    combined['Education'] = combined['Education'].map({'Graduate':1,'Not Graduate':0})


# In[ ]:


def process_employment():
    global combined
    combined['Self_Employed'] = combined['Self_Employed'].map({'Yes':1,'No':0})


# In[ ]:


def process_income():
    global combined
    combined['Total_Income'] = combined['ApplicantIncome'] + combined['CoapplicantIncome']
    combined.drop(['ApplicantIncome','CoapplicantIncome'], axis=1, inplace=True)


# In[ ]:


def process_loan_amount():
    global combined
    combined['Debt_Income_Ratio'] = combined['Total_Income'] / combined['LoanAmount']


# In[ ]:


combined['Loan_Amount_Term'].value_counts()


# In[ ]:


print(combined.head())


# In[ ]:


approved_term = data_train[data_train['Loan_Status']=='Y']['Loan_Amount_Term'].value_counts()
unapproved_term = data_train[data_train['Loan_Status']=='N']['Loan_Amount_Term'].value_counts()
df = pd.DataFrame([approved_term,unapproved_term])
df.index = ['Approved','Unapproved']
df.plot(kind='bar', stacked=True, figsize=(15,8))


# In[ ]:


def process_loan_term():
    global combined
    combined['Very_Short_Term'] = combined['Loan_Amount_Term'].map(lambda t: 1 if t<=60 else 0)
    combined['Short_Term'] = combined['Loan_Amount_Term'].map(lambda t: 1 if t>60 and t<180 else 0)
    combined['Long_Term'] = combined['Loan_Amount_Term'].map(lambda t: 1 if t>=180 and t<=300  else 0)
    combined['Very_Long_Term'] = combined['Loan_Amount_Term'].map(lambda t: 1 if t>300 else 0)
    combined.drop('Loan_Amount_Term', axis=1, inplace=True)


# In[ ]:


def process_credit_history():
    global combined
    combined['Credit_History_Bad'] = combined['Credit_History'].map(lambda c: 1 if c==0 else 0)
    combined['Credit_History_Good'] = combined['Credit_History'].map(lambda c: 1 if c==1 else 0)
    combined['Credit_History_Unknown'] = combined['Credit_History'].map(lambda c: 1 if c==2 else 0)
    combined.drop('Credit_History', axis=1, inplace=True)


# In[ ]:


process_gender()


# In[ ]:


def process_property():
    global combined
    property_dummies = pd.get_dummies(combined['Property_Area'], prefix='Property')
    combined = pd.concat([combined, property_dummies], axis=1)
    combined.drop('Property_Area', axis=1, inplace=True)


# In[ ]:
    

process_gender()
process_martial_status()
process_dependents()
process_education()
process_employment()


# In[ ]:


process_dependents()


# In[ ]:


process_education()


# In[ ]:


process_employment()
process_income()
process_loan_amount()
process_loan_term()
process_credit_history()
process_property()
process_property()


# In[ ]:


process_income()


# In[ ]:


process_loan_amount()


# In[ ]:


process_loan_term()


# In[ ]:


process_credit_history()


# In[ ]:


process_property()


# In[ ]:


combined[60:70]


# In[ ]:


def feature_scaling(df):
    df -= df.min()
    df /= df.max()
    return df


# In[ ]:


combined['LoanAmount'] = feature_scaling(combined['LoanAmount'])
combined['Total_Income'] = feature_scaling(combined['Total_Income'])
combined['Debt_Income_Ratio'] = feature_scaling(combined['Debt_Income_Ratio'])


# In[ ]:


combined[200:210]


# In[ ]:


from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel


# In[ ]:


def compute_score(clf, X, y, scoring='accuracy'):
    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)
    return np.mean(xval)


# In[ ]:


def recover_train_test_target():
    global combined, data_train
    targets = data_train['Loan_Status'].map({'Y':1,'N':0})
    train = combined.head(614)
    test = combined.iloc[614:]
    return train, test, targets


# In[ ]:


train, test, targets = recover_train_test_target()


# In[ ]:


clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')
clf = clf.fit(train, targets)


# In[ ]:


features = pd.DataFrame()
features['Feature'] = train.columns
features['Importance'] = clf.feature_importances_
features.sort_values(by=['Importance'], ascending=False, inplace=True)
features.set_index('Feature', inplace=True)


# In[ ]:


features.plot(kind='bar', figsize=(20, 10))


# In[ ]:


model = SelectFromModel(clf, prefit=True)
train_reduced = model.transform(train)
train_reduced.shape


# In[ ]:


test_reduced = model.transform(test)
test_reduced.shape


# In[ ]:


parameters = {'bootstrap': False,
              'min_samples_leaf': 3,
              'n_estimators': 50,
              'min_samples_split': 10,
              'max_features': 'sqrt',
              'max_depth': 6}

model = RandomForestClassifier(**parameters)
model.fit(train, targets)


# In[ ]:


compute_score(model, train, targets, scoring='accuracy')


# In[ ]:


output = model.predict(test).astype(int)
df_output = pd.DataFrame()
aux = pd.read_csv('test.csv')
df_output['Loan_ID'] = aux['Loan_ID']
df_output['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(output)
df_output[['Loan_ID','Loan_Status']].to_csv('output.csv',index=False)


# In[ ]:


pd.read_csv('output.csv')


